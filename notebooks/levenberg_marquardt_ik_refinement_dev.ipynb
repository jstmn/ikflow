{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d619eab0",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook analyzes the use of levenberg-marquardt for IK refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from jrl.utils import set_seed, make_text_green_or_red, evenly_spaced_colors\n",
    "from jrl.math_utils import geodesic_distance_between_quaternions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ikflow.model_loading import get_ik_solver\n",
    "\n",
    "torch.set_printoptions(linewidth=300, precision=6, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7298640",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"panda__full__lp191_5.25m\"\n",
    "POS_ERROR_THRESHOLD = 0.001\n",
    "ROT_ERROR_THRESHOLD = 0.01\n",
    "\n",
    "ikflow_solver, _ = get_ik_solver(MODEL_NAME)\n",
    "robot = ikflow_solver.robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626aeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_converged(robot, qs, target_poses, i):\n",
    "    # check error\n",
    "    pose_realized = robot.forward_kinematics_batch(qs)\n",
    "    pos_errors = torch.norm(pose_realized[:, 0:3] - target_poses[:, 0:3], dim=1)\n",
    "    rot_errors = geodesic_distance_between_quaternions(target_poses[:, 3:], pose_realized[:, 3:])\n",
    "    #\n",
    "    converged = pos_errors.max().item() < POS_ERROR_THRESHOLD and rot_errors.max().item() < ROT_ERROR_THRESHOLD\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.max().item(), 6), \"\\t\", round(rot_errors.max().item(), 6), \"\\t\", pos_errors.data)\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.max().item(), 6), \"\\t\", round(rot_errors.max().item(), 6),)\n",
    "    #\n",
    "    # converged = pos_errors.mean().item() < POS_ERROR_THRESHOLD and rot_errors.mean().item() < ROT_ERROR_THRESHOLD\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.mean().item(), 6), \"\\t\", round(rot_errors.mean().item(), 6), \"\\t\", pos_errors.data, rot_errors.data)\n",
    "    return converged, pos_errors, rot_errors\n",
    "\n",
    "\n",
    "def plot_errors(all_pos_errors, all_rot_errors):\n",
    "    fig, (axl, axr) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    fig.suptitle(f\"Levenberg-Marquardt IK Convergence\")\n",
    "\n",
    "    axl.set_title(f\"Positional errors\")\n",
    "    axl.grid(alpha=0.2)\n",
    "    axl.set_xlabel(\"iteration\")\n",
    "    axl.set_ylabel(\"error (m)\")\n",
    "\n",
    "    axr.set_title(f\"Rotational errors\")\n",
    "    axr.grid(alpha=0.2)\n",
    "    axr.set_xlabel(\"iteration\")\n",
    "    axr.set_ylabel(\"error (rad)\")\n",
    "\n",
    "    n = all_pos_errors[0].shape[0]\n",
    "    xs = np.arange(n)\n",
    "    colors = evenly_spaced_colors(int(1.5*len(all_pos_errors)))\n",
    "    axl.plot([0, xs[-1]], [POS_ERROR_THRESHOLD, POS_ERROR_THRESHOLD], label=\"threshold\", color=\"green\")\n",
    "    axr.plot([0, xs[-1]], [ROT_ERROR_THRESHOLD, ROT_ERROR_THRESHOLD], label=\"threshold\", color=\"green\")\n",
    "    for i, (pos_errors, rot_errors) in enumerate(zip(all_pos_errors, all_rot_errors)):\n",
    "        axl.scatter(xs, pos_errors.cpu().numpy(), label=f\"iteration {i}\", s=15, color=colors[i])\n",
    "        axr.scatter(xs, rot_errors.cpu().numpy(), label=f\"iteration {i}\", s=15, color=colors[i])\n",
    "    # plt.savefig(f\"lma_errors_{i}.pdf\", bbox_inches=\"tight\")\n",
    "    # axl.legend()\n",
    "    axr.legend()\n",
    "    plt.show()\n",
    "\n",
    "def debug_dist_to_jlims(robot, qs):\n",
    "    \"\"\" test with:\n",
    "    qs_random, _ = ikflow_solver.robot.sample_joint_angles_and_poses(5) \n",
    "    debug_dist_to_jlims(robot, torch.tensor(qs_random))\n",
    "    \"\"\"\n",
    "    \n",
    "    mins = 100*torch.ones(len(qs))\n",
    "    eps = 1e-5\n",
    "    for i, (l, u) in enumerate(robot.actuated_joints_limits):\n",
    "        assert torch.min(qs[:, i]) > l - eps\n",
    "        assert torch.max(qs[:, i]) < u + eps, f\"{torch.max(qs[:, i])} !< {u}\"\n",
    "        mins = torch.minimum(mins, torch.abs(qs[:, i] - l))\n",
    "        mins = torch.minimum(mins, torch.abs(qs[:, i] - u))\n",
    "    print(\"distances to joint limits:\", mins)\n",
    "    return mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127d333-57e7-4a6b-a8ec-58cefd46ee53",
   "metadata": {},
   "source": [
    "### Difficult config solution 1: Additional ikflow solutions for each target pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa0cee-1608-4843-8574-acd5a18cfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "# n_solutions = 10\n",
    "n_solutions = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "# repeat_count = 1  # converged in 27 iterations\n",
    "# repeat_count = 2  # converged in 10 iterations\n",
    "# repeat_count = 3  # converged in 10 iterations\n",
    "# repeat_count = 4  # converged in 10 iterations\n",
    "repeat_count = 5  # converged in 1 iterations\n",
    "# repeat_count = 10  # converged in 1 iterations\n",
    "\n",
    "# --- target pose\n",
    "_, target_poses_original = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses_original, dtype=torch.float32, device=\"cuda:0\")\n",
    "target_poses_tiled = target_poses.repeat((repeat_count, 1))\n",
    "\n",
    "# target_poses: tensor([[ 0.555446,  0.504079,  0.332677,  0.012954,  0.487856,  0.854263,  0.179060],\n",
    "#         [-0.281688,  0.697731, -0.016917,  0.030757, -0.934636, -0.219964, -0.277716],\n",
    "#         [ 0.623912,  0.485226,  0.128579,  0.375592,  0.023773,  0.851167,  0.365896]], device='cuda:0')\n",
    "\n",
    "\n",
    "# --- ik solution seeds\n",
    "t0_ikf = time()\n",
    "q0 = ikflow_solver.generate_ik_solutions(target_poses, None)\n",
    "print(f\"Got {len(q0)} ik solutions from IKFlow in {time() - t0_ikf} seconds\")\n",
    "q = q0.clone()\n",
    "\n",
    "\n",
    "print(\"\\ntarget_poses:\", target_poses)\n",
    "print(\"q0:          \", q)\n",
    "print()\n",
    "for j in range(n_solutions):\n",
    "    qs_sol_j = q[j + torch.arange(0, q.shape[0], n_solutions, device=device), :]\n",
    "    debug_dist_to_jlims(robot, qs_sol_j)\n",
    "print()\n",
    "\n",
    "\n",
    "def one_q_is_valid(qs_j, target_pose):\n",
    "    assert qs_j.shape[0] == target_pose.shape[0], f\"{qs_j.shape} != {target_pose.shape}\"\n",
    "    assert target_pose.shape[1] == 7\n",
    "    _, pos_errors, rot_errors = check_converged(robot, qs_j, target_pose, j)\n",
    "    valids = torch.logical_and(pos_errors < POS_ERROR_THRESHOLD, rot_errors < ROT_ERROR_THRESHOLD)\n",
    "    print(\" \", valids, pos_errors, rot_errors)\n",
    "    return valids.any()\n",
    "    \n",
    "\n",
    "q = q.to(device)\n",
    "target_poses = target_poses.to(device)\n",
    "target_poses_tiled = target_poses_tiled.to(device)\n",
    "converged = False\n",
    "t0 = time()\n",
    "\n",
    "for i in range(30):\n",
    "\n",
    "    # qprev = q.clone()\n",
    "    # q = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses_tiled, q, clamp_to_joint_limits=False)\n",
    "    q = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses_tiled, q)\n",
    "    # print(\"diff:\", q - qprev)\n",
    "    # assert False\n",
    "\n",
    "    converged_notes = torch.zeros(n_solutions, dtype=torch.bool, device=device)\n",
    "    # print(\"\\ni:\", i)\n",
    "\n",
    "    for j in range(n_solutions):\n",
    "        # print(\"\\n  j:\", j)\n",
    "        qs_sol_j = q[j + torch.arange(0, q.shape[0], n_solutions, device=device), :]\n",
    "        target_poses_j = target_poses[j].repeat((repeat_count, 1))  # todo: use .expand(), which is 0 copy\n",
    "        converged_notes[j] = one_q_is_valid(qs_sol_j, target_poses_j)\n",
    "        # print(\"  qs_sol_j: \", qs_sol_j)\n",
    "\n",
    "    # print(\"\\nconverged_notes:\", converged_notes)\n",
    "    converged = converged_notes.all().item()\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "    # converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "    # print(pos_errors.data, rot_errors.data)\n",
    "    # all_pos_errors.append(pos_errors)\n",
    "    # all_rot_errors.append(rot_errors)\n",
    "    # if converged:\n",
    "    #     break\n",
    "\n",
    "print(f\"\\nperformed {i+1} optimization steps in {time() - t0} seconds\")\n",
    "print()\n",
    "if not converged:\n",
    "    # n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    # print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i+1} iterations ({converged_notes.sum().item()}/{converged_notes.numel()} valid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i+1} iterations\", True))\n",
    "\n",
    "# plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f18cf",
   "metadata": {},
   "source": [
    "### Difficult config solution 2: Add noise to configs solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "n_solutions = 10\n",
    "# n_solutions = 3\n",
    "device = \"cpu\"\n",
    "repeat_count = 1  # performed 20 optimization steps in 0.5879652500152588 seconds\n",
    "# repeat_count = 100 # performed 20 optimization steps in 1.2729570865631104 seconds\n",
    "\n",
    "# --- target pose\n",
    "_, target_poses_original = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses_original, dtype=torch.float32, device=\"cuda:0\")\n",
    "target_poses_tiled = target_poses.repeat((repeat_count, 1))\n",
    "\n",
    "# target_poses: tensor([[ 0.555446,  0.504079,  0.332677,  0.012954,  0.487856,  0.854263,  0.179060],\n",
    "#         [-0.281688,  0.697731, -0.016917,  0.030757, -0.934636, -0.219964, -0.277716],\n",
    "#         [ 0.623912,  0.485226,  0.128579,  0.375592,  0.023773,  0.851167,  0.365896]], device='cuda:0')\n",
    "\n",
    "\n",
    "# --- ik solution seeds\n",
    "t0_ikf = time()\n",
    "qs0_original = ikflow_solver.generate_ik_solutions(target_poses, None)\n",
    "print(f\"Got {n_solutions} ik solutions from IKFlow in {time() - t0_ikf} seconds\")\n",
    "q0 = qs0_original.repeat((repeat_count, 1))\n",
    "# noise = torch.randn_like(q0[n_solutions:, :]) * 0.025\n",
    "# noise = torch.randn_like(q0[n_solutions:, :]) * 0.05\n",
    "noise = torch.randn_like(q0[n_solutions:, :]) * 0.1\n",
    "q0[n_solutions:, :] += noise\n",
    "q0 = robot.clamp_to_joint_limits(q0)\n",
    "q = q0.clone()\n",
    "\n",
    "\n",
    "print(\"\\ntarget_poses:\", target_poses)\n",
    "print(\"q0:          \", q)\n",
    "print(\"noise:       \", noise)\n",
    "print()\n",
    "for j in range(n_solutions):\n",
    "    qs_sol_j = q[j + torch.arange(0, q.shape[0], n_solutions, device=device), :]\n",
    "    debug_dist_to_jlims(robot, qs_sol_j)\n",
    "print()\n",
    "\n",
    "\n",
    "def one_q_is_valid(qs_j, target_pose):\n",
    "    assert qs_j.shape[0] == target_pose.shape[0], f\"{qs_j.shape} != {target_pose.shape}\"\n",
    "    assert target_pose.shape[1] == 7\n",
    "    _, pos_errors, rot_errors = check_converged(robot, qs_j, target_pose, j)\n",
    "    valids = torch.logical_and(pos_errors < POS_ERROR_THRESHOLD, rot_errors < ROT_ERROR_THRESHOLD)\n",
    "    # print(\" \", valids, pos_errors, rot_errors)\n",
    "    return valids.any()\n",
    "    \n",
    "\n",
    "q = q.to(device)\n",
    "target_poses = target_poses.to(device)\n",
    "target_poses_tiled = target_poses_tiled.to(device)\n",
    "converged = False\n",
    "t0 = time()\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    qprev = q.clone()\n",
    "    # q = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses_tiled, q, clamp_to_joint_limits=False)\n",
    "    q = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses_tiled, q, clamp_to_joint_limits=True)\n",
    "    # print(\"diff:\", q - qprev)\n",
    "    # assert False\n",
    "\n",
    "    converged_notes = torch.zeros(n_solutions, dtype=torch.bool, device=device)\n",
    "    # print(\"\\ni:\", i)\n",
    "\n",
    "    for j in range(n_solutions):\n",
    "        # print(\"\\n  j:\", j)\n",
    "        qs_sol_j = q[j + torch.arange(0, q.shape[0], n_solutions, device=device), :]\n",
    "        target_poses_j = target_poses[j].repeat((repeat_count, 1))  # todo: use .expand(), which is 0 copy\n",
    "        converged_notes[j] = one_q_is_valid(qs_sol_j, target_poses_j)\n",
    "        # print(\"  qs_sol_j: \", qs_sol_j)\n",
    "\n",
    "    # print(\"\\nconverged_notes:\", converged_notes)\n",
    "    converged = converged_notes.all().item()\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "    # converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "    # print(pos_errors.data, rot_errors.data)\n",
    "    # all_pos_errors.append(pos_errors)\n",
    "    # all_rot_errors.append(rot_errors)\n",
    "    # if converged:\n",
    "    #     break\n",
    "\n",
    "print(f\"\\nperformed {i+1} optimization steps in {time() - t0} seconds\")\n",
    "print()\n",
    "if not converged:\n",
    "    # n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    # print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({converged_notes.sum().item()}/{converged_notes.numel()} valid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "# plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fb9c0",
   "metadata": {},
   "source": [
    "## Default optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "# n_solutions = 40\n",
    "n_solutions = 200\n",
    "_, target_poses = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses, dtype=torch.float32, device=\"cuda:0\")\n",
    "\n",
    "qs = ikflow_solver.generate_ik_solutions(target_poses, None)\n",
    "# set_seed(10) # n_solutions = 40\n",
    "# qs = ikflow_solver.generate_ik_solutions(target_poses, None)\n",
    "\n",
    "converged = False\n",
    "i = 0\n",
    "all_pos_errors = []\n",
    "all_rot_errors = []\n",
    "\n",
    "_, pos_errors, rot_errors = check_converged(robot, qs, target_poses, \"init\")\n",
    "all_pos_errors.append(pos_errors)\n",
    "all_rot_errors.append(rot_errors)\n",
    "\n",
    "alphas = torch.ones((n_solutions, 1), dtype=torch.float32, device=\"cuda:0\")\n",
    "\n",
    "thresh = 0.015\n",
    "above_thresh_scale = 0.5\n",
    "alphas[pos_errors > thresh] = above_thresh_scale\n",
    "\n",
    "while not converged and i < 20:\n",
    "\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs)\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.1)           # 53 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.25)          # 20 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.75)          # 27 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.5)         # 10 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alphas=alphas)\n",
    "\n",
    "    converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "    all_pos_errors.append(pos_errors)\n",
    "    all_rot_errors.append(rot_errors)\n",
    "\n",
    "    # \n",
    "    alphas[pos_errors > thresh] = above_thresh_scale\n",
    "    alphas[pos_errors < thresh] = 1.0\n",
    "\n",
    "    # print(i, converged)\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2cfa5",
   "metadata": {},
   "source": [
    "# Negative mining for difficult configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_solutions = 5000\n",
    "\n",
    "set_seed(0)\n",
    "_, target_poses = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses, dtype=torch.float32, device=\"cuda:0\")\n",
    "q0s = ikflow_solver.generate_ik_solutions(target_poses, None)\n",
    "qs = q0s.clone()\n",
    "for _ in range(8):\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs)\n",
    "\n",
    "# select non converged solutions\n",
    "converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "difficult_idxs = torch.logical_and(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD)\n",
    "difficult_poses = target_poses[difficult_idxs]\n",
    "difficult_qs = q0s[difficult_idxs]\n",
    "\n",
    "print(difficult_poses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9a18d",
   "metadata": {},
   "source": [
    "### Difficult config solution 1: lower alpha when far from solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_errors = []\n",
    "all_rot_errors = []\n",
    "\n",
    "qs = difficult_qs.clone()\n",
    "_, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, \"init\")\n",
    "all_pos_errors.append(pos_errors)\n",
    "all_rot_errors.append(rot_errors)\n",
    "\n",
    "\n",
    "alphas = torch.ones((len(qs), 1), dtype=torch.float32, device=\"cuda:0\")\n",
    "thresh = 0.015\n",
    "# above_thresh_scale = 0.5\n",
    "above_thresh_scale = 0.25\n",
    "alphas[pos_errors > thresh] = above_thresh_scale\n",
    "\n",
    "\n",
    "i = 0\n",
    "converged = False\n",
    "while not converged and i < 20:\n",
    "\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs)\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.1)           # 53 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.25)          # 20 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.75)          # 27 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.5)         # 10 iterations\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alphas=alphas)\n",
    "\n",
    "    converged, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, i)\n",
    "    all_pos_errors.append(pos_errors)\n",
    "    all_rot_errors.append(rot_errors)\n",
    "\n",
    "    print(pos_errors)\n",
    "\n",
    "    # \n",
    "    alphas[pos_errors > thresh] = above_thresh_scale\n",
    "    alphas[pos_errors < thresh] = 1.0\n",
    "\n",
    "    # print(i, converged)\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c36b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c106ee123d7af531b7acc4f77c56e24741db8737a45cbfd984346f16de511ef0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
