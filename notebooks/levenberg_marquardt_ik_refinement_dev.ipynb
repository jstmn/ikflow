{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d619eab0",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook analyzes the use of levenberg-marquardt for IK refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext wurlitzer\n",
    "# import os\n",
    "# os.chdir(\"../\")\n",
    "# print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from jrl.utils import set_seed, make_text_green_or_red, evenly_spaced_colors\n",
    "from jrl.math_utils import geodesic_distance_between_quaternions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ikflow.model_loading import get_ik_solver\n",
    "\n",
    "\n",
    "torch.set_printoptions(linewidth=300, precision=6, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7298640",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"panda__full__lp191_5.25m\"\n",
    "POS_ERROR_THRESHOLD = 0.001\n",
    "ROT_ERROR_THRESHOLD = 0.01\n",
    "\n",
    "ikflow_solver, _ = get_ik_solver(MODEL_NAME)\n",
    "robot = ikflow_solver.robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626aeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_converged(robot, qs, target_poses, i):\n",
    "    # check error\n",
    "    pose_realized = robot.forward_kinematics_batch(qs)\n",
    "    pos_errors = torch.norm(pose_realized[:, 0:3] - target_poses[:, 0:3], dim=1)\n",
    "    rot_errors = geodesic_distance_between_quaternions(target_poses[:, 3:], pose_realized[:, 3:])\n",
    "    #\n",
    "    converged = pos_errors.max().item() < POS_ERROR_THRESHOLD and rot_errors.max().item() < ROT_ERROR_THRESHOLD\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.max().item(), 6), \"\\t\", round(rot_errors.max().item(), 6), \"\\t\", pos_errors.data)\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.max().item(), 6), \"\\t\", round(rot_errors.max().item(), 6),)\n",
    "    #\n",
    "    # converged = pos_errors.mean().item() < POS_ERROR_THRESHOLD and rot_errors.mean().item() < ROT_ERROR_THRESHOLD\n",
    "    # print(\"solve_lma\", i, converged, round(pos_errors.mean().item(), 6), \"\\t\", round(rot_errors.mean().item(), 6), \"\\t\", pos_errors.data, rot_errors.data)\n",
    "    return converged, pos_errors, rot_errors\n",
    "\n",
    "\n",
    "def plot_errors(all_pos_errors, all_rot_errors):\n",
    "    fig, (axl, axr) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    fig.suptitle(f\"Levenberg-Marquardt IK Convergence\")\n",
    "\n",
    "    axl.set_title(f\"Positional errors\")\n",
    "    axl.grid(alpha=0.2)\n",
    "    axl.set_xlabel(\"iteration\")\n",
    "    axl.set_ylabel(\"error (m)\")\n",
    "\n",
    "    axr.set_title(f\"Rotational errors\")\n",
    "    axr.grid(alpha=0.2)\n",
    "    axr.set_xlabel(\"iteration\")\n",
    "    axr.set_ylabel(\"error (rad)\")\n",
    "\n",
    "    n = all_pos_errors[0].shape[0]\n",
    "    xs = np.arange(n)\n",
    "    colors = evenly_spaced_colors(int(1.5*len(all_pos_errors)))\n",
    "    axl.plot([0, xs[-1]], [POS_ERROR_THRESHOLD, POS_ERROR_THRESHOLD], label=\"threshold\", color=\"green\")\n",
    "    axr.plot([0, xs[-1]], [ROT_ERROR_THRESHOLD, ROT_ERROR_THRESHOLD], label=\"threshold\", color=\"green\")\n",
    "    for i, (pos_errors, rot_errors) in enumerate(zip(all_pos_errors, all_rot_errors)):\n",
    "        axl.scatter(xs, pos_errors.cpu().numpy(), label=f\"iteration {i}\", s=15, color=colors[i])\n",
    "        axr.scatter(xs, rot_errors.cpu().numpy(), label=f\"iteration {i}\", s=15, color=colors[i])\n",
    "    # plt.savefig(f\"lma_errors_{i}.pdf\", bbox_inches=\"tight\")\n",
    "    # axl.legend()\n",
    "    axr.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fb9c0",
   "metadata": {},
   "source": [
    "## Default optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "# n_solutions = 40\n",
    "n_solutions = 200\n",
    "_, target_poses = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses, dtype=torch.float32, device=\"cuda:0\")\n",
    "\n",
    "qs = ikflow_solver.solve_n_poses(ys=target_poses)\n",
    "# set_seed(10) # n_solutions = 40\n",
    "# qs = ikflow_solver.solve_n_poses(ys=target_poses)\n",
    "\n",
    "converged = False\n",
    "i = 0\n",
    "all_pos_errors = []\n",
    "all_rot_errors = []\n",
    "\n",
    "_, pos_errors, rot_errors = check_converged(robot, qs, target_poses, \"init\")\n",
    "all_pos_errors.append(pos_errors)\n",
    "all_rot_errors.append(rot_errors)\n",
    "\n",
    "alphas = torch.ones((n_solutions, 1), dtype=torch.float32, device=\"cuda:0\")\n",
    "\n",
    "thresh = 0.015\n",
    "above_thresh_scale = 0.5\n",
    "alphas[pos_errors > thresh] = above_thresh_scale\n",
    "\n",
    "while not converged and i < 20:\n",
    "\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs)\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.1)           # 53 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.25)          # 20 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.75)          # 27 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alpha=0.5)         # 10 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs, alphas=alphas)\n",
    "\n",
    "    converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "    all_pos_errors.append(pos_errors)\n",
    "    all_rot_errors.append(rot_errors)\n",
    "\n",
    "    # \n",
    "    alphas[pos_errors > thresh] = above_thresh_scale\n",
    "    alphas[pos_errors < thresh] = 1.0\n",
    "\n",
    "    # print(i, converged)\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2cfa5",
   "metadata": {},
   "source": [
    "# Negative mining for difficult configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_solutions = 5000\n",
    "\n",
    "set_seed(0)\n",
    "_, target_poses = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses, dtype=torch.float32, device=\"cuda:0\")\n",
    "q0s = ikflow_solver.solve_n_poses(ys=target_poses)\n",
    "qs = q0s.clone()\n",
    "for _ in range(8):\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses, qs)\n",
    "\n",
    "# select non converged solutions\n",
    "converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "difficult_idxs = torch.logical_and(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD)\n",
    "difficult_poses = target_poses[difficult_idxs]\n",
    "difficult_qs = q0s[difficult_idxs]\n",
    "\n",
    "print(difficult_poses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9a18d",
   "metadata": {},
   "source": [
    "### Difficult config solution 1: lower alpha when far from solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_errors = []\n",
    "all_rot_errors = []\n",
    "\n",
    "qs = difficult_qs.clone()\n",
    "_, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, \"init\")\n",
    "all_pos_errors.append(pos_errors)\n",
    "all_rot_errors.append(rot_errors)\n",
    "\n",
    "\n",
    "alphas = torch.ones((len(qs), 1), dtype=torch.float32, device=\"cuda:0\")\n",
    "thresh = 0.015\n",
    "# above_thresh_scale = 0.5\n",
    "above_thresh_scale = 0.25\n",
    "alphas[pos_errors > thresh] = above_thresh_scale\n",
    "\n",
    "\n",
    "i = 0\n",
    "converged = False\n",
    "while not converged and i < 20:\n",
    "\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs)\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.1)           # 53 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.25)          # 20 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.75)          # 27 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.5)         # 10 iterations\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alphas=alphas)\n",
    "\n",
    "    converged, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, i)\n",
    "    all_pos_errors.append(pos_errors)\n",
    "    all_rot_errors.append(rot_errors)\n",
    "\n",
    "    print(pos_errors)\n",
    "\n",
    "    # \n",
    "    alphas[pos_errors > thresh] = above_thresh_scale\n",
    "    alphas[pos_errors < thresh] = 1.0\n",
    "\n",
    "    # print(i, converged)\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f18cf",
   "metadata": {},
   "source": [
    "### Difficult config solution 2: Add noise to solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "n_solutions = 10\n",
    "device = \"cpu\"\n",
    "repeat_count = 5\n",
    "\n",
    "_, target_poses = ikflow_solver.robot.sample_joint_angles_and_poses(n_solutions, only_non_self_colliding=True, tqdm_enabled=False)\n",
    "target_poses = torch.tensor(target_poses, dtype=torch.float32, device=\"cuda:0\")\n",
    "target_poses_tiled = target_poses.repeat((repeat_count, 1))\n",
    "# target_poses_tiled = target_poses.clone()\n",
    "\n",
    "\n",
    "qs0 = ikflow_solver.solve_n_poses(ys=target_poses)\n",
    "qs_with_noise0 = qs0.repeat((repeat_count, 1))\n",
    "qs_with_noise0[n_solutions:, :] += torch.randn_like(qs_with_noise0[n_solutions:, :]) * 0.05\n",
    "# qs_with_noise0[n_solutions:, :] += torch.randn_like(qs_with_noise0[n_solutions:, :]) * 0\n",
    "qs_with_noise = qs_with_noise0.clone()\n",
    "\n",
    "print(\"target_poses_tiled:\", target_poses_tiled)\n",
    "print(\"qs_with_noise:\", qs_with_noise)\n",
    "print()\n",
    "\n",
    "\n",
    "# for j in range(n_solutions):\n",
    "#     qs_sol_j = qs_with_noise[j + torch.arange(0, qs_with_noise.shape[0], n_solutions, device=device), :]\n",
    "#     print(\"\\n  j:\", j)\n",
    "#     print(\"  qs_sol_j:\", qs_sol_j)\n",
    "# assert False\n",
    "\n",
    "# converged = False\n",
    "# i = 0\n",
    "# all_pos_errors = []\n",
    "# all_rot_errors = []\n",
    "\n",
    "# _, pos_errors, rot_errors = check_converged(robot, qs, target_poses, \"init\")\n",
    "# all_pos_errors.append(pos_errors)\n",
    "# all_rot_errors.append(rot_errors)\n",
    "\n",
    "qs_with_noise = qs_with_noise.to(device)\n",
    "target_poses = target_poses.to(device)\n",
    "target_poses_tiled = target_poses_tiled.to(device)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    qprev = qs_with_noise.clone()\n",
    "    qs_with_noise = robot.inverse_kinematics_single_step_levenburg_marquardt(target_poses_tiled, qs_with_noise)\n",
    "\n",
    "    # print(\"diff:\", qs_with_noise - qprev)\n",
    "    # assert False\n",
    "\n",
    "    converged_notes = torch.zeros(n_solutions, dtype=torch.bool, device=device)\n",
    "\n",
    "    print(\"\\ni:\", i)\n",
    "\n",
    "    for j in range(n_solutions):\n",
    "        qs_sol_j = qs_with_noise[j + torch.arange(0, qs_with_noise.shape[0], n_solutions, device=device), :]\n",
    "        print(\"\\n  j:\", j)\n",
    "        # print(\"  qs_sol_j:\", qs_sol_j)\n",
    "\n",
    "        target_poses_j = target_poses[j].repeat((qs_sol_j.shape[0], 1))\n",
    "        _, pos_errors, rot_errors = check_converged(robot, qs_sol_j, target_poses_j, j)\n",
    "\n",
    "        valids = torch.logical_and(pos_errors < POS_ERROR_THRESHOLD, rot_errors < ROT_ERROR_THRESHOLD)\n",
    "        print(\" \", valids, pos_errors, rot_errors)\n",
    "        # valids_rows = valids.any(dim=1)\n",
    "        # print(\" valids_rows:\", valids_rows)\n",
    "\n",
    "        converged_notes[j] = valids.any()\n",
    "\n",
    "    print(\"converged_notes:\", converged_notes)\n",
    "    converged = converged_notes.all().item()\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "    # converged, pos_errors, rot_errors = check_converged(robot, qs, target_poses, i)\n",
    "    # print(pos_errors.data, rot_errors.data)\n",
    "    # all_pos_errors.append(pos_errors)\n",
    "    # all_rot_errors.append(rot_errors)\n",
    "    # if converged:\n",
    "    #     break\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    # n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    # print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations (/ invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "# plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_errors = []\n",
    "all_rot_errors = []\n",
    "\n",
    "qs = difficult_qs.clone()\n",
    "_, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, \"init\")\n",
    "all_pos_errors.append(pos_errors)\n",
    "all_rot_errors.append(rot_errors)\n",
    "\n",
    "\n",
    "alphas = torch.ones((len(qs), 1), dtype=torch.float32, device=\"cuda:0\")\n",
    "thresh = 0.015\n",
    "# above_thresh_scale = 0.5\n",
    "above_thresh_scale = 0.25\n",
    "alphas[pos_errors > thresh] = above_thresh_scale\n",
    "\n",
    "\n",
    "i = 0\n",
    "converged = False\n",
    "while not converged and i < 20:\n",
    "\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs)\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.1)           # 53 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.25)          # 20 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.75)          # 27 iterations\n",
    "    # qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alpha=0.5)         # 10 iterations\n",
    "    qs = robot.inverse_kinematics_single_step_levenburg_marquardt(difficult_poses, qs, alphas=alphas)\n",
    "\n",
    "    converged, pos_errors, rot_errors = check_converged(robot, qs, difficult_poses, i)\n",
    "    all_pos_errors.append(pos_errors)\n",
    "    all_rot_errors.append(rot_errors)\n",
    "\n",
    "    print(pos_errors)\n",
    "\n",
    "    # \n",
    "    alphas[pos_errors > thresh] = above_thresh_scale\n",
    "    alphas[pos_errors < thresh] = 1.0\n",
    "\n",
    "    # print(i, converged)\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "if not converged:\n",
    "    n_invalid = torch.logical_or(pos_errors > POS_ERROR_THRESHOLD, rot_errors > ROT_ERROR_THRESHOLD).sum().item()\n",
    "    print(make_text_green_or_red(f\"Failed to converge after {i} iterations ({n_invalid}/{len(qs)} invalid)\", False))\n",
    "else:\n",
    "    print(make_text_green_or_red(f\"Converged after {i} iterations\", True))\n",
    "\n",
    "plot_errors(all_pos_errors, all_rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c36b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c106ee123d7af531b7acc4f77c56e24741db8737a45cbfd984346f16de511ef0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
